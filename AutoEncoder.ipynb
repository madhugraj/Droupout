{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoEncoder.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMDTHiZTjmsTt4UxoTa8Q7E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madhugraj/Droupout/blob/master/AutoEncoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vfSvYI9mwtx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15ADNzx0ngC7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "#config = tf.compat.v1.ConfigProto( device_count = {'GPU': 1 , 'CPU': 56} ) \n",
        "#sess = tf.compat.v1.Session(config=config) \n",
        "#tf.compat.v1.keras.backend.set_session(sess)\n",
        "\n",
        "from keras.models import load_model\n",
        "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Activation,concatenate,GlobalAveragePooling2D,Flatten,MaxPooling2D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.optimizers import Adam\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "from keras.datasets import cifar10\n",
        "from tqdm import tqdm\n",
        "from keras.utils import plot_model\n",
        "import os\n",
        "#os.environ[\"PATH\"] += os.pathsep + r'C:\\Program Files (x86)\\graphviz-2.38\\bin/'\n",
        "\n",
        "import cv2 as cv2\n",
        "from imutils import paths\n",
        "import random\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "import glob,progressbar,tqdm\n",
        "from keras.preprocessing.image import load_img,array_to_img,img_to_array\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iC1ZzDcmwBVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip /content/Small_Data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHoEFVaTwQcl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip /content/test.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnU5nUHPwXiT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train2= sorted(glob.glob(r'/content/Small_Data/*.*'))\n",
        "valid_data= sorted(glob.glob(r'/content/test/*.*'))\n",
        "\n",
        "x_tr =[]\n",
        "valid =[]\n",
        "\n",
        "def img_preprocess(img):\n",
        "    img=load_img(img,color_mode='grayscale',target_size=(512,512))\n",
        "    img= img_to_array(img).astype('float32')/255\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyD9Lm-sxI5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for img in tqdm(x_train2):\n",
        "    x_tr.append(img_preprocess(img))\n",
        "    \n",
        "x_tr= np.array(x_tr)\n",
        " \n",
        "\n",
        "\n",
        "for img in tqdm(valid_data):\n",
        "    valid.append(img_preprocess(img))\n",
        "    \n",
        "valid= np.array(valid)\n",
        "\n",
        "print('Train Shape:',x_tr.shape)\n",
        "print('Test Shape:',valid.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCdflMmpxPVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_in = Input(shape=(512,512,1),name= 'InputLayer')\n",
        "\n",
        "# 1x1 convolution\n",
        "conv1 = Conv2D(128, (1,1),padding='same',activation='relu',name='Conv_1x1')(layer_in)\n",
        "\n",
        "#3x3 conv\n",
        "conv3 =  Conv2D(128, (1,1),padding='same',activation='relu')(layer_in)\n",
        "conv3 =  Conv2D(128, (3,3),padding='same',activation='relu',name='Conv_3x3')(conv3)\n",
        "\n",
        "#5x5 conv\n",
        "conv5 =  Conv2D(128,(1,1),padding='same',activation='relu')(layer_in)\n",
        "conv5 =  Conv2D(128,(5,5),padding='same',activation='relu',name='Conv_5x5')(conv5)\n",
        "\n",
        "#3x3 Max pooling\n",
        "\n",
        "pool = MaxPooling2D((3,3),strides=(1,1),padding='same',name='max_pool_3x3')(layer_in)\n",
        "pool =  Conv2D(128,(1,1),padding='same',activation='relu')(pool)\n",
        "output= concatenate([conv1,conv3,conv5,pool],axis=-1)\n",
        "\n",
        "encode = MaxPooling2D((2,2),padding='same',name='pool1')(output)\n",
        "encode = Conv2D(256,(2,2),activation='relu',padding='same',name='concat_256')(encode)\n",
        "\n",
        "## Latent View\n",
        "latent_view    = MaxPooling2D((2, 2), padding='same',name='latent_view')(encode)\n",
        "\n",
        "decode = UpSampling2D((2,2), name='Upsampling2')(encode)\n",
        "decode = Conv2D(128,(2,2),activation='relu',padding='same', name='conv3')(decode)\n",
        "decode = Conv2D(1,(2,2),activation='sigmoid',padding='same',name='conv4')(decode)\n",
        "\n",
        "autoencoder= Model(inputs= layer_in,outputs=decode)\n",
        "autoencoder.compile(optimizer='Adam',loss='mse',metrics=['mse','accuracy'])\n",
        "\n",
        "autoencoder.summary()\n",
        "plot_model(autoencoder, to_file='model_new_1x1.jpeg', show_layer_names=True, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4HC8vVNxYK4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights_path= r'/content/Weights/'\n",
        "\n",
        "\n",
        "'''\n",
        "es_cb = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
        "chkpt = weights_path + \"Autoencoder_adam_y_512_512_epoch_{}.h5\"\n",
        "cp_cb = ModelCheckpoint(filepath = chkpt, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "\n",
        "history = autoencoder.fit(x_tr, x_tr,\n",
        "                            batch_size=8,\n",
        "                            epochs=10,\n",
        "                            verbose=1,\n",
        "                            callbacks=[es_cb, cp_cb],\n",
        "                            shuffle=True)\n",
        "\n",
        "sample_test= load_img(valid,color_mode=\"grayscale\",target_size=(512,512))\n",
        "sample_test =img_to_array(sample_test)\n",
        "sample_test = sample_test.astype('float32')/255.\n",
        "\n",
        "sample_test = np.expand_dims(sample_test,axis=0)\n",
        "prection = autoencoder.predict([sample_test,sample_test])\n",
        "\n",
        "f,ax = plt.subplots(1,2,figsize=(20,10))\n",
        "ax[0].imshow(np.seqeeze(sample_test),cmap='gray')\n",
        "ax[1].imshow(prection.reshape(512,512),cmap='gray')\n",
        "plt.show()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9i5DVbD0qbB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(10):\n",
        "    autoencoder.fit(x_tr,x_tr,epochs=5,batch_size=8)\n",
        "    autoencoder.save(weights_path + \"Autoencoder_adam_y_512_512_epoch_{}.h5\",format(i*10))\n",
        "    ### prediction\n",
        "    \n",
        "    sample_test= load_img(valid,color_mode=\"grayscale\",target_size=(512,512))\n",
        "    sample_test =img_to_array(sample_test)\n",
        "    sample_test = sample_test.astype('float32')/255.\n",
        "    \n",
        "    sample_test = np.expand_dims(sample_test,axis=0)\n",
        "    prection = autoencoder.predict([sample_test,sample_test])\n",
        "    \n",
        "    f,ax = plt.subplots(1,2,figsize=(20,10))\n",
        "    ax[0].imshow(np.seqeeze(sample_test),cmap='gray')\n",
        "    ax[1].imshow(prection.reshape(512,512),cmap='gray')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}